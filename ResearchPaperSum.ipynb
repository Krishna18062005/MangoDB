{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching paper from the URL...\n",
      "Paper fetched. Summarizing...\n",
      "WARNING:tensorflow:From c:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 200, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of the U.S. for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots. We'll feature the best shots from across the globe.\n",
      "\n",
      "Extracting keywords...\n",
      "Keywords: ['world', 'research']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Function to fetch paper content from a URL using Selenium\n",
    "def fetch_paper(url):\n",
    "    \"\"\"\n",
    "    Fetch and parse the research paper from a URL using Selenium.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up the WebDriver (you may need to install a web driver)\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        driver.implicitly_wait(10)  # Wait up to 10 seconds for elements to load\n",
    "\n",
    "        # You can increase the wait time if the page is slow or uses JS rendering\n",
    "        time.sleep(5)  # Add additional wait for dynamic content to load\n",
    "\n",
    "        # Get the page source after JavaScript has rendered the content\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Extract the content (assuming it's inside <article> tags or similar)\n",
    "        content = ''\n",
    "        for p in soup.find_all('p'):\n",
    "            content += p.get_text()\n",
    "\n",
    "        driver.quit()  # Close the browser after extracting content\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching paper: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to summarize the research paper\n",
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    Summarizes the text using a pre-trained transformer model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        summarizer = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "        # Handle very large text by breaking it into smaller chunks\n",
    "        chunk_size = 1000  # Process text in chunks\n",
    "        text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "        summary = \"\"\n",
    "        for chunk in text_chunks:\n",
    "            summary += summarizer(chunk, max_length=200, min_length=50, do_sample=False)[0]['summary_text']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract keywords (using basic NLTK methods for simplicity)\n",
    "def extract_keywords(text):\n",
    "    \"\"\"\n",
    "    Extracts basic keywords (nouns) from the text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        keywords = [word for word, pos in pos_tags if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "        return keywords\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting keywords: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main function to execute the entire process\n",
    "def process_paper(url):\n",
    "    \"\"\"\n",
    "    Fetches the paper from the URL, summarizes it, and extracts keywords.\n",
    "    \"\"\"\n",
    "    print(\"Fetching paper from the URL...\")\n",
    "    paper_content = fetch_paper(url)\n",
    "    if not paper_content:\n",
    "        print(\"Failed to fetch paper.\")\n",
    "        return\n",
    "\n",
    "    print(\"Paper fetched. Summarizing...\")\n",
    "    summary = summarize_text(paper_content)\n",
    "    if summary:\n",
    "        print(\"\\nSummary:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"Failed to summarize the paper.\")\n",
    "\n",
    "    print(\"\\nExtracting keywords...\")\n",
    "    keywords = extract_keywords(paper_content)\n",
    "    print(\"Keywords:\", keywords)\n",
    "\n",
    "# Example URL (replace with actual paper URL)\n",
    "paper_url = \"https://www.researchgate.net/publication/349470771_Using_Machine_Learning_for_Heart_Disease_Prediction\"  # Replace with the URL of a real research paper\n",
    "\n",
    "process_paper(paper_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching paper from the PDF...\n",
      "Paper fetched. Summarizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 200, but your input_length is only 192. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 200, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Edge-based Heart Disease Prediction using Federated Learning. Proceedings of 2024 International Conference on Cognitive Robotics and Intelligent Systems. IEEE Xplore Part Number: CFP24UD1-ART; ISBN: 979-8-3503-7274-8.Machine learning is being implemented to classify the severity of the heart disease. It is in the ratioof four in five cardiovascular deaths disease among the people. Methods like K-Nearest Algorithm (KNN), DecisionTree (DT) and Navie                produced from healthcare industries are being implemented.A shared model of federated learningthat makes its averaging process more efficient. Data mining method that collects all the data and store it in one place centrally. The data is from an updated version of LASSO (Least Absolute Shrinkage and Selection) algorithm.The proposed model has achieved 93.4% of accuracy levels by integrating the LASSO algorithm. Using federated averaging algorithm, the updated algorithm has been updated in recent years. The most difficult task is gathering the weights that are processed in the edge device.The article is organized as follows: Section II describes literature review related to heart security and privacy. Section III details how the model is trained cooperatively while the training data is distributed across different edge-based users or clients. Section IV explains theimplemented works of the architecture for the weighted aggregate.This work will suggest an efficient model that is based on a Federated Learning-based approach. It will predict whether a 979-8-3503-7274-8/24/$31.00 ©2024 IEEE 29450043501.4202.83206SNIBOR-CCI/9011.00.01:IOD, EEEI, SVM, LR, and Federated Average.A study achieves an accuracy of 90.11% on the UCI benchmark. The unique approach lies in reducing latency by bringing Hybrid Edge-assisted Machine Learning Approach with ROC progressively closer to end-users. The results show the significance of Adaboost, SVM, KNN, and Decision Trees on the Cleveland dataset.An edge-based system that predicts heart disease that. utilizes IOT has attained an accuracy of 95% in heart disease. agging, LR, SVM, and XGBoost accuracy of 80%. Maybe in future works of this project would autoimmuneon diverse datasets, yielding a high accuracy of 90.5% [3]. possibly ameliorate scalability and accuracy of its prediction.A paper that introduces Advancements inpredictingHeart. that uses federated averaging algorithm which uses age, sex, and some parameters from the UCI ML repository. Dataset achieves over an impressive accuracy of 95.8% based on the data.A study over predicting heart disease in near future. A detailed information about the cardio vascular disease that uses machine learning and deep parameters in thedataset is given in theTable 1 below. The values in the Cleveland dataset contains categoricaldomain as because it offers the optionto analyse the things in values and continuous values.An accuracy of 90.5% has been obtained from the data. The study not only emphasizes high generalization and. stability but also addresses the bottleneck issues commonly S.NO ATTRIBUTESfaced in medical data analysis. While achieving promising.1 Resting bp results, this study also highlights the challenge. of predicting specific disease types.The federated averaging algorithm is used to predict heart rate max. in decision tree, random forest, K-nearest neighbor, Naviebayes, MLP and ANOVA approaches. Efficient heart 4 age 4 agedisease prediction system gives good results and helps in area area of study.Here in thisproject this algorithm enables us to train the model on decentralized data while preserving data privacy. The methods include wrappermethods, embedded and filter methods. Feature selection helps in simplifying models and reducing computing time. Edge based computing is also a core part for this project where the weights are collected.In wrapper method it uses the machine learning model to produce an enhanced accuracy machine learning algorithm's performance that is being evaluated. Process involves cleaning and preparing the data before it is fed into involve in feature selection as a part of the model-building process.LASSO is a way of regression method which.adds a term to the traditional linear regression of its cost. This model handles imbalanced data along with noisy data function. This term is proportional to the values of the data points. DBSCAN effectively handle another feature selection algorithm is thaLASSO is a procedure in ML and statistics, where some relevant features are selected. It is found that by using LASSO, it has more advantages than selecting features from the large set of features is selected. Thedetailed system architecture is given below.Feature selection ensures that sensitive information in local datasets is not exposed during the model training process. Central server thataggregatesthe selected features from all its clients to update the global model. By transmitting only the selected features rather than the entire dataset, federated learning with featureselection reduces communication costs.The federated learning system with few feature selection is tested and evaluated to see how well it works. Feature selection helps focus on the mostrelevant information, potentially improving model accuracy, convergence speed, and interpretability. Robust security measures are implemented to safeguard the Federated learning process, ensuring that the communicationand aggregation of feature information are secure and private.The edge device in smart phones has adequate amount of computational power. The machine learning frameworks and libraries are compatible with edge devices. These type of related models are developed in TensorFlow and pysyft, which are all included in the learning framework. The results show that the correlation coefficients between the models and the dataset are perfect.In this study, heart disease is predicted using federated. learnlearn. algorithm. In Fig.4. the box plot gives us the summary statistic line that is directly proportional to the variable when changed. The 0 provides data about the central tendency and the spread of the values.The proposed model can be used to diagnose heart diseases. The future works include reducing the overhead problems. The proposed model produced an enhanced prediction performance and overall time consumption. It was deployed with an accuracy level of 93.4% for heart disease prediction.\"Cardiovascular Disease Prediction Using Hybrid-Random-Forest-Linear- Model (HRFLM)\" in IEEEAccess, vol. 7, pp. 81542-81554, 2019. \"Edge-based Heart Disease Prediction Device using Internet of Things,\" 2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC), Salem, India, 2022.The validation accuracy of about93.4% is achieved with the 2023.use of LASSO feature selection algorithm and 88% of the 88% algorithm. The 2023 International Conference on Self-Sustainable Artificial Intelligence Systems (ICSSAS) will be held in New York.Proceedings of 2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS 2024)IEEE Xplore Part Number: CFP24UD1-ART; ISBN: 979-8-3503-7274-8. Authorized licensed use limited to: Zhejiang University.\"TrustFedHealth: Federated Learning with 25th International Conference on Computer and InformationHomomorphic Encryption and Blockchain for Heart Disease Technology (ICCIT), Cox's Bazar, Bangladesh, 2022, pp. 1086-1091. \"Ischemia prediction via ECG using MLP and RBF predictors with                [11] P. Sharma and S. Sharma, \"A Comprehensive Study Of The Machine ANFIS classifiers\"Disease,\" 2023 6th International Conference on Contemporary 10.1109/ICNC.2011.6022179. (DDP): A mining based statistical measuring approach for disease. \"Horizontal Federated Random Forest for Heart Disease Detection,\" 2022 IEEE 10th Region 10 Humanitarian Jaipur, India, 2014, pp. 1-6.\"Blood Viscosity based Heart Disease Risk Conference on Bioinformatics and Biomedicine (BIBM), Seoul, Korea. \"Prediction Model in Edge/Fog Computing,\" 2019 11th International (South), 2020, pp. 1805-1812. Based on Network Representation Learning,\" 2020 IEEE International. \"Heart Disease Computing Methodologies and Communication (ICCMC), Erode, India, 2022.Authorized licensed use limited to: Zhejiang University. Restrictions apply. Downloaded on September 08,2024 at 13:28:28 UTC from IEEE Xplore. Back to Mail Online home. Back To the page you came from.\n",
      "\n",
      "Extracting keywords...\n",
      "Keywords: ['Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', 'Heart', 'Disease', 'Prediction', 'Federated', 'Learning', 'Ancy', 'Jenifer', 'J', 'Research', 'Scholar', 'CSE', 'Getzi', 'Jeba', 'Leelipushpam', 'Paulraj', 'Gladston', 'Rosario.M', 'Karunya', 'Institute', 'Technology', 'Associate', 'Professor', 'CSE', 'Karunya', 'Student', 'CSE', 'Karunya', 'Institute', 'Science', 'Coimbatore', 'India', 'Institute', 'Technology', 'Science', 'Technology', 'Science', 'karunya.edu', 'Coimbatore', 'India', 'getzi', '@', 'karunya.edu', 'Coimbatore', 'India', 'gladstonrosario', '@', 'karunya.edu', 'M.', 'Shilpa', 'Aarthi', 'Immanuel', 'JohnRaja', 'Jebadurai', 'Snowlin', 'Preethi', 'Janani', 'Assisstant', 'professor', 'CSE', 'Karuya', 'Professor', 'CSE', 'Karunya', 'Institute', 'Assisstant', 'professor', 'CSE', 'Karuya', 'Institute', 'Technology', 'Science', 'Technology', 'Science', 'Coimbatore', 'Institute', 'Technology', 'Science', 'Coimbatore', 'India', 'India', 'immanueljohnraja', '@', 'gmail.com', 'Coimbatore', 'India', 'shilpaaarthi', '@', 'karunya.edu', 'jananifrn', '@', 'gmail.com', 'Abstract—', 'Cardiovasculardiseases', 'areone', 'causes', 'person', 'heart', 'disease', 'death', 'Prediction', 'diseases', 'bit', 'prediction', 'model', 'combination', 'complex', 'fields', 'analysis', 'features', 'classification', 'feature', 'millions', 'deaths', 'heart', 'selection', 'techniques', 'severity', 'heart', 'disease.And', 'ratioof', 'deaths', 'disease', 'people', 'data', 'mining', 'aredue', 'heart', 'failure', 'times', 'networks', 'Methods', 'K-Nearest', 'decisions', 'predictions', 'amount', 'data', 'Neighbour', 'Algorithm', 'KNN', 'DecisionTree', 'DT', 'Navie', 'healthcare', 'industries', 'machine', 'learning', 'Bayes', 'NB', 'severity', 'hype', 'machine', 'disease', 'feature', 'selection', 'algorithm', 'diseasedetection', 'data', 'LASSO', 'Least', 'Absolute', 'Shrinkage', 'Selectionoperator', 'place', 'data', 'hospital', 'privacy', 'security', 'concerns', 'knowledge', 'prediction', 'heart', 'disease', 'itbecomes', 'methods', 'data', 'data', 'store', 'place', 'problem', 'statement', 'researchwork', 'thismodel', 'work', 'tests', 'approach', 'detectionmodel', 'prediction', 'model', 'effectiveness', 'A', 'model', 'moretechniques', 'model', 'efficiency', 'algorithm', 'aggregates', 'updates', 'So', 'analysis', 'model', 'clients', 'edge', 'device', 'privacy', 'performance', 'level', 'accuracyof93.4', '%', 'security', 'results', 'model', '%', 'accuracy', 'levels', 'LASSO', 'contributionfrom', 'paper', 'feature', 'selectionalgorithm', 'edge', 'heart', 'disease', 'prediction', 'device', 'Keywords—', 'Heart', 'Disease', 'Prediction', 'Federated', 'Averaging', 'Algorithm', 'Distributed', 'Training', 'Logistic', 'Regression', 'Data', '•', 'approach', 'privacy', 'Privacy', 'security', '•', 'Compared', 'feature', 'selection', 'INTRODUCTION', 'theaccuracy', 'levels', 'Heart', 'disease', 'causes', 'death', '•', 'Using', 'algorithm', 'years', 'task', 'weights', 'edge', 'device', 'patient', 'data', 'records', 'cloud', 'users', 'data', 'processing', 'latency', 'bandwidth', 'challenge', 'patients', 'Section', 'II', 'literature', 'review', 'heart', 'security', 'privacy.So', 'learning', 'paradigm', 'disease', 'prediction', 'learning', 'Section', 'III', 'details', 'model', 'training', 'data', 'architecture', 'system', 'layers', 'users', 'clients', 'Again', 'SectionIV', 'works', 'architecture', 'aggregate', 'values', 'parameters', 'system.Section', 'V', 'results', 'server', ']', 'system', 'conditions', 'Section', 'VI', 'aspects', 'problem', 'statements', 'research', 'work', 'work', 'model', 'approach', '©2024', 'IEEE', 'IOD', '|', 'EEEI', '|', 'SNIBOR', 'CCI', 'tnegilletnI', 'dna', 'scitoboR', 'ecnerefnoC', 'lanoitanretnI', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply.Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', 'II', 'LITERATURE', 'SURVEY', 'Optimizing', 'Heart', 'Disease', 'Detection', 'Machine', 'Learning', 'Approach', ']', 'work', 'heart', 'disease', 'detection', 'approach', 'research', 'literature', 'Federated', 'Machine', 'Learning', 'Approach', 'SVM', 'LR', 'Federated', 'Average', 'Approach', 'Employes', 'Black', 'Widow', 'Optimization', 'Algorithmbasedon', 'parameters', 'age', 'sex', 'Adaboost', 'SVM', 'KNN', 'decision', 'tree', 'factors', 'accuracy', '%', 'Cleveland', 'dataset', 'study', 'accuracy', '%', 'UCI', 'benchmark', ']', 'study', ']', 'approach', 'latency', 'Machine', 'Learning', 'Approach', 'ROC', 'computation', 'closer', 'end-users', 'curve', 'analysis', 'Black', 'Widow', 'Optimization', 'detection', 'capabilities', ']', 'results', 'significance', 'Adaboost', 'SVM', 'KNN', 'Decision', 'Trees', 'Cleveland', 'edge', 'efficiency', 'heart', 'disease', 'dataset', 'accuracy', '%', ']', 'prediction', 'models', 'edge', 'learning', 'model', 'internet', 'things', 'prediction', 'heart', 'disease', 'integrates', 'Fuzzy', 'GBDT', 'Bagging', 'LR', 'SVM', 'XGBoost', 'accuracy', '%', 'works', 'project', 'datasets', 'accuracy', '%', ']', 'scalability', 'accuracy', 'prediction', 'Andanother', 'system', 'heart', 'disease', ']', 'IOT', 'accuracy', '%', 'heart', 'disease', 'diversity', 'algorithms', 'need', 'dataset', '%', 'gait', 'dataset', 'latency', 'implementing', 'strategies', 'heart', 'bandwidth', 'lowercost', '[', ']', '.Also', 'system', 'prediction', 'datasets', 'application', 'domains', 'learning', 'model', ']', 'landscape', 'heart', 'disease', 'model', 'quest', 'precise', 'tools', 'implementing', 'feature', 'selection', 'algorithms', 'impact', 'healthcare', 'outcomes', 'uses', 'classifications', 'efficiency', 'system', 'heart', 'diseaseso', 'model', 'works', 'evolving', 'time', 'applications', ']', 'phase', 'heart', 'disease', 'prediction', 'methodologies', 'approaches', 'paper', 'Advancements', 'inpredictingHeart', 'impact', 'healthcare', 'diagnostics', 'Disease', 'algorithm', 'treatment', 'planning', 'parameters', 'age', 'sex', 'parameters', 'UCI', 'ML', 'repository', 'III', 'METHODOLOGY', 'study', 'vector', 'machine', ']', 'regression', 'Federated', 'Averaging', 'Algorithm', 'A.', 'Dataset', 'accuracy', '%', 'study', 'Cleveland', 'dataset', 'UCI', 'benchmark', ']', 'approach', 'Kaggle', 'machine', 'repository', 'data', 'storage', 'data', 'privacy', 'parameters', 'parameter', 'targetvalue', 'effectiveness', 'SVM', 'person', 'Federated', 'Logistic', 'Regression', ']', 'A', 'study', 'heart', 'disease', 'future', 'information', 'cardio', 'disease', 'machine', 'learning', 'parameters', 'thedataset', 'learninginterprets', 'data', 'way', 'process', 'advantage', 'B', 'Attribute', 'Information', 'DLT', 'model', 'things', 'health', 'values', 'Cleveland', 'dataset', 'domain', 'optionto', 'things', 'values', 'values', 'dataset', 'speed', 'precision', ']', 'pre', 'techniques', 'values', 'dataset', 'ML', 'model', 'Value', 'defines', 'paper', 'AI', 'model', 'person', 'defines', 'person', 'detectingmanyclasses', 'heart', 'disease', 'prediction', 'heart', 'disease', 'model', '%', 'InternetofThings', 'IoT', ']', 'diverse', 'data', 'training', 'data', 'levels', 'ECG', 'readings', 'employing', 'training', 'Fuzzy', 'GBDT', 'Bagging', 'LR', 'ANN', 'SVM', 'XGBoost', 'MLP', 'accuracy', '%', 'TABLE', 'Dataset', ']', 'study', 'generalization', 'stability', 'bottleneck', 'issues', 'S.NO', 'ATTRIBUTES', 'data', 'analysis', 'bp', 'results', ']', 'study', 'challenge', 'disease', 'types', 'way', 'Sex', 'research', 'QMBC', 'accuracy', '%', 'algorithms', 'regression', 'Chest', 'pain', 'decision', 'tree', 'K-nearest', 'neighbor', 'Navie', 'MLP', 'ANOVA', 'approaches', ']', 'heart', 'age', 'disease', 'prediction', 'system', 'results', 'area', 'Fasting', 'blood', 'sugar', 'specialists', 'field', 'model', 'patient', 'serum', 'cholestr', 'theresults', ']', 'result', '©2024', 'IEEE', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply.Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', 'heart', 'rate', 'max', 'anigma', 'ST', 'depression', 'Slope', 'peak', 'exercise', 'ST', 'segment', 'Number', 'vessels', 'Thalassemia', 'C.', 'Federated', 'averaging', 'algorithm', 'model', 'execution', 'purpose', 'security', 'privacy', 'data', 'records', 'patients', 'thisproject', 'algorithm', 'model', 'data', 'data', 'privacy', 'model', 'D.', 'Edge', 'model', 'edge', 'computing', 'core', 'part', 'project', 'weights', 'models', 'edge', 'averaging', 'algorithm', 'feature', 'selection', 'Fig.1', 'Thesystem', 'architecture', 'algorithm', 'accuracy', 'levels', 'algorithms', 'Feature', 'selection', 'models', 'computation', 'time', 'methods', 'IV', 'EXPERIMENTAL', 'SETUP', 'selection', 'methods', 'methods', 'methods', 'filter', 'method', 'A.Pre', 'processing', 'data', 'pre', 'processing', 'features', 'chosen', 'machine', 'step', 'kind', 'ML', 'analysis', 'algorithm', 'method', 'machine', 'model', 'accuracy', 'machine', 'algorithm', 'performance', 'performance', 'process', 'feature', 'subsets', 'methods', 'data', 'involve', 'feature', 'selection', 'part', 'themodel', 'training', 'pre-processing', 'process', 'data', 'cleaning', 'values', 'mean', 'values', 'feature', 'selection', 'algorithm', 'process', 'detection', 'treatment', 'pre', 'processing', 'stage', 'end', 'cause', 'deviation', 'datapoints', 'rest', 'Next', 'evaluation', 'stage', 'model', 'performance', 'data', 'transformation', 'normalization', 'dimensionality', 'reduction', 'robustness', 'noise', 'reduction', 'values', 'ones', 'data', 'reduction', 'computation', 'feature', 'selection', 'techniques', 'feature', 'selection', 'dimensionality', 'LASSO', 'shrinkage', 'reduction', 'selection', 'operator', 'way', 'regression', 'method', 'term', 'regression', 'cost', 'model', 'data', 'data', 'function', 'term', 'values', 'duplicate', 'data', 'preprocessing.In', 'advance', 'regression', 'coefficients', 'feature', 'LASSO', 'data', 'model', 'DBSCAN', 'coefficient', 'shrink', 'technique', 'data', 'cluster', 'features', 'feature', 'density', 'data', 'points', 'DBSCAN', 'feature', 'selection', 'algorithm', 'information', 'noisy', 'datapoints', 'outliers', 'points', 'dependency', 'variables', 'cluster', 'noise', 'values', 'information', 'variable', 'information', 'target', 'B', 'Models', 'system', 'architecture', 'Fig.1', 'feature', 'selection', 'procedure', 'ML', 'statistics', 'LASSO', 'advantages', 'features', 'set', 'features', 'information', 'Decentralized', 'Computation', 'aim', 'information', 'learning', 'models', 'features', 'models', 'performance', 'devices', 'data', 'overfitting', 'interpretability', 'feature', 'selection', 'client', 'dataset', 'Privacy', 'consideration', '©2024', 'IEEE', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply.Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', 'learning', 'Feature', 'selection', 'information', 'datasets', 'model', 'training', 'process', 'Aggregation', 'Central', 'Server', 'server', 'aggregatesthe', 'itsclients', 'model', 'Aggregation', 'methods', 'secure', 'computaion', 'features', 'dataset', 'feature', 'selection', 'reduces', 'communication', 'costs', 'environments', 'Model', 'Efficiency', 'Feature', 'selection', 'information', 'model', 'accuracy', 'convergence', 'speed', 'interpretability', 'security', 'measures', 'learning', 'process', 'communication', 'aggregation', 'feature', 'information', 'secure', 'Federated', 'Learning', 'Framework', 'learning', 'framework', 'modifications', 'feature', 'selection', 'Fig.2', 'Correlation', 'Evaluation', 'learning', 'system', 'feature', 'selection', 'violinplots', 'inFig.3.displays', 'distribution', 'assess', 'performance', 'accuracy', 'communication', 'parameter', 'Thalach', 'efficiency', 'convergence', 'speed', 'body', 'plot', 'probability', 'density', 'data', 'C.', 'Hardware', 'software', 'requirements', 'hardware', 'edge', 'device', 'phone', 'amount', 'power', 'Memory', 'RAM', 'data', 'samples', 'etc.', 'connectivity', 'options', 'Wi-Fi', 'networks', 'communication', 'edge', 'devices', 'servers', 'software', 'requirements', 'OS', 'edge', 'devices', 'machine', 'learning', 'frameworks', 'libraries', 'edge', 'device', 'frameworks', 'tensorflow', 'pysyft', 'D.', 'Model', 'Training', 'model', 'weights', 'server', 'updates', 'model', 'type', 'models', 'TensorFlow', 'pysyft', 'learning', 'framework', 'V', 'EXPERIMENTAL', 'RESULTS', 'AND', 'ANALYSIS', 'Fig.2', 'correlation', 'coefficients', 'Fig.3Violin', 'plot', 'parameters', 'dataset', 'correlation', 'matrix', 'ranges', 'value', 'matrix', 'tell', 'correlation', 'value', 'ranges', 'Fig.4', 'box', 'plot', 'line', 'proportional', 'data', 'tendency', 'spread', 'values', 'correlation', 'data', 'age', 'heart', 'disease', 'parameters', 'coefficients', '©2024', 'IEEE', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply.Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', 'TABLEII', 'Analysisof', 'feature', 'selection', 'FEATURE', 'SELECTION', 'ACCURACY', 'ALGORITHM', 'USED', 'LASSO', 'ALGORITHM', '%', 'MUTUALINFORMATION', '%', 'ALGORITHM', 'VI', 'CONCLUSION', 'study', 'heart', 'disease', 'learning', 'approach', 'results', 'heart', 'disease', 'prediction', 'accuracy', 'levels', 'machine', 'classification', 'algorithms', 'algorithm', 'yields', 'results', 'accuracy', 'addition', 'learning', 'feature', 'selection', 'algorithm', 'LASSO', 'information', 'LASSO', 'algorithm', 'results', 'Fig.4', 'box', 'plot', 'information', 'algorithms', 'learning', 'LASSO', 'feature', 'selection', 'model', 'prediction', 'performance', 'time', 'consumption', 'model', 'accuracy', 'level', '%', 'model', 'heart', 'diseases', 'future', 'problems', 'REFERENCES', ']', 'S.', 'Mohan', 'C.', 'Thirumalai', 'G.', 'Srivastava', 'Heart', 'Disease', 'Prediction', 'Using', 'Hybrid', 'Machine', 'Learning', 'Techniques', 'IEEE', 'Access', 'vol', 'pp', 'doi', ']', 'Abbaraju', 'Sai', 'Sathwik', 'Beebi', 'Naseeba', 'Nagendra', 'Panini', 'Challa', 'Cardiovascular', 'Disease', 'Prediction', 'Using', 'Hybrid-Random-Forest-', 'Linear-', 'Model', 'HRFLM', 'IEEE', 'World', 'Conference', 'Applied', 'Intelligence', 'Computing', 'AIC', ']', 'A.Jenifer', 'al.', 'Heart', 'Disease', 'Prediction', 'Device', 'Internet', 'Things', 'International', 'Conference', 'Applied', 'Artificial', 'Intelligence', 'Computing', 'ICAAIC', 'Salem', 'India', 'pp', 'doi', ']', 'C.', 'D.', 'M', 'R.', 'Senapati', 'Heart', 'Disease', 'Prediction', 'Model', 'Machine', 'Learning', 'Approach', 'OITS', 'International', 'Conference', 'Information', 'Technology', 'OCIT', 'Bhubaneswar', 'India', 'pp', 'doi', ']', 'M.', 'Jahir', 'Pasha', 'Kiraniwale', 'Aejaz', 'Ahmed', 'Shaikh', 'Mohammed', 'Amair', 'Fig.5', 'bar', 'plot', 'Sunni', 'Arshad', 'Hussain', 'Shaik', 'Fayaz', 'Diagnosis', 'Human', 'Cardiovascular', 'Disease', 'Using', 'Machine', 'Learning', 'Parametric', 'Optimization', 'Techniques', 'International', 'Conference', 'Self', 'Sustainable', 'Artificial', 'Intelligence', 'Systems', 'ICSSAS', 'validation', 'accuracy', 'about93.4', '%', 'use', 'LASSO', 'feature', 'selection', 'algorithm', '%', ']', 'G.', 'Muhammad', 'al.', 'Prognosis', 'Accuracy', 'Ischemic', 'accuracy', 'information', 'algorithm', 'Disease', 'Using', 'K', 'Nearest', 'Neighbor', 'Algorithm', 'Robust', 'Approach', 'IEEE', 'Access', 'vol', 'pp', 'table', 'fig.5.', 'finding', 'doi', 'feature', 'selection', 'algorithm', 'model', ']', 'C.', 'Chakraborty', 'A.', 'Kishor', 'Patient-', 'heart', 'disease', 'learning', 'approach', 'Centric', 'Monitoring', 'Using', 'Computational', 'Health', 'Systems', 'IEEE', 'edge', 'Transactions', 'Computational', 'Social', 'Systems', 'vol', 'pp', 'Dec.', 'doi', '©2024', 'IEEE', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply.Proceedings', 'International', 'Conference', 'Cognitive', 'Robotics', 'Intelligent', 'Systems', 'ICC', 'ROBINS', 'IEEE', 'Xplore', 'Part', 'Number', 'ISBN', '[', ']', 'M.', 'V', 'K.', 'AL', 'P.', 'B', 'R.', 'P', 'K.', 'B', 'M.', 'G', 'Appropriate', ']', 'S.', 'Rao', 'S.', 'Kulkarni', 'S.', 'Mehta', 'P.', 'Tawde', 'Edge', 'Feature', 'Selection', 'Techniques', 'Renal', 'Disease', 'Classification', 'Heart', 'Rate', 'Monitoring', 'System', 'RNN', 'LSTM', 'Models', 'First', 'International', 'Conference', 'Advances', 'International', 'Conference', 'Computing', 'Communication', 'Electrical', 'Electronics', 'Computational', 'Intelligence', 'ICAEECI', 'Networking', 'Technologies', 'ICCCNT', 'Delhi', 'India', 'pp', 'doi', 'Tiruchengode', 'India', 'pp', 'doi', ']', 'S.', 'Rahman', 'M.', 'M.', 'Hasan', 'A.', 'K.', 'Sarkar', 'Machine', 'Learning', ']', 'B.', 'T.', 'H.', 'Dang', 'P.', 'H.', 'Luan', 'V.', 'D.', 'T.', 'Ngan', 'N.', 'T.', 'Trong', 'P.', 'T.', 'Duy', 'Deep', 'Neural', 'Network', 'Techniques', 'Heart', 'Disease', 'Prediction', 'V.', '-H.', 'Pham', 'TrustFedHealth', 'International', 'Conference', 'Computer', 'Information', 'Homomorphic', 'Encryption', 'Blockchain', 'Heart', 'Disease', 'Technology', 'ICCIT', 'Cox', 'Bazar', 'Bangladesh', 'pp', 'Prediction', 'Smart', 'Healthcare', 'International', 'Conference', 'doi', 'Advanced', 'Technologies', 'Communications', 'ATC', 'Da', 'Nang', ']', 'H.', 'Tonekabonipour', 'A.', 'Emam', 'M.', 'Teshnelab', 'M.', 'A.', 'Shoorehdeli', 'Vietnam', 'pp', 'doi', 'Ischemia', 'prediction', 'ECG', 'MLP', 'RBF', 'predictors', 'P.', 'Sharma', 'S.', 'Sharma', 'Comprehensive', 'Study', 'Machine', 'ANFIS', 'classifiers', 'Seventh', 'International', 'Conference', 'Natural', 'Learning', 'Federated', 'Learning', 'Approach', 'Heart', 'Computation', 'Shanghai', 'China', 'pp', 'doi', 'Disease', 'International', 'Conference', 'Contemporary', 'Informatics', 'IC3I', 'Gautam', 'Buddha', 'Nagar', 'India', ']', 'R.', 'Nagavelli', 'C.', 'V.', 'Guru', 'Rao', 'Degree', 'Disease', 'possibility', 'pp', 'doi', 'DDP', 'mining', 'measuring', 'approach', 'disease', '[', ']', 'S.', 'M.', 'Jalal', 'M.', 'R.', 'Hasan', 'M.', 'A.', 'Haque', 'M.', 'G.', 'R.', 'Alam', 'prediction', 'health', 'care', 'data', 'mining', 'International', 'Conference', 'Horizontal', 'Federated', 'Random', 'Forest', 'Heart', 'Disease', 'Detection', 'Recent', 'Advances', 'Innovations', 'Engineering', 'ICRAIE-2014', 'Decentralized', 'Local', 'Data', 'IEEE', 'Region', 'Humanitarian', 'Jaipur', 'India', 'pp', 'doi', 'Technology', 'Conference', 'R10-HTC', 'Hyderabad', 'India', 'pp', 'X.', 'Su', 'Z', 'H.', 'Yi', 'Prediction', 'LncRNA-Disease', 'Associations', 'doi', 'Network', 'Representation', 'Learning', 'IEEE', 'International', '[', ']', 'R.', 'Latha', 'P.', 'Vetrivelan', 'Blood', 'Viscosity', 'Heart', 'Disease', 'Risk', 'Conference', 'Bioinformatics', 'Biomedicine', 'BIBM', 'Seoul', 'Korea', 'Prediction', 'Model', 'Edge/Fog', 'Computing', 'International', 'South', 'pp', 'doi', 'Conference', 'Communication', 'Systems', 'Networks', 'COMSNETS', 'Bengaluru', 'India', 'pp', 'doi', ']', 'K.', 'B', 'S', 'D.', 'M', 'N.', 'K', 'Federated', 'Learning', 'Approach', 'Heart', 'Disease', 'Prediction', 'International', 'Conference', '[', ']', 'K.', 'S.', 'L.', 'Prasanna', 'N.', 'P.', 'Challa', 'J.', 'Nagaraju', 'Heart', 'Disease', 'Computing', 'Methodologies', 'Communication', 'ICCMC', 'Erode', 'Prediction', 'Reinforcement', 'Learning', 'Technique', 'Third', 'India', 'pp', 'doi', 'International', 'Conference', 'Advances', 'Electrical', 'Computing', 'Communication', 'Technologies', 'ICAECT', 'Bhilai', 'India', 'pp', 'doi', '©2024', 'IEEE', 'Authorized', 'Zhejiang', 'University', 'September', 'UTC', 'IEEE', 'Xplore', 'Restrictions', 'apply']\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Function to fetch paper content from a PDF using pdfplumber\n",
    "def fetch_paper_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using pdfplumber.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = ''\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                content += page.extract_text()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching paper from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to summarize the text using a pre-trained transformer model\n",
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    Summarizes the text using a pre-trained transformer model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        summarizer = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "        # Handle very large text by breaking it into smaller chunks\n",
    "        chunk_size = 1000  # Process text in chunks\n",
    "        text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "        summary = \"\"\n",
    "        for chunk in text_chunks:\n",
    "            summary += summarizer(chunk, max_length=200, min_length=50, do_sample=False)[0]['summary_text']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract keywords (using basic NLTK methods for simplicity)\n",
    "def extract_keywords(text):\n",
    "    \"\"\"\n",
    "    Extracts basic keywords (nouns) from the text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        keywords = [word for word, pos in pos_tags if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "        return keywords\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting keywords: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main function to execute the entire process\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Fetches the paper from the PDF, summarizes it, and extracts keywords.\n",
    "    \"\"\"\n",
    "    print(\"Fetching paper from the PDF...\")\n",
    "    paper_content = fetch_paper_from_pdf(pdf_path)\n",
    "    if not paper_content:\n",
    "        print(\"Failed to fetch paper from the PDF.\")\n",
    "        return\n",
    "\n",
    "    print(\"Paper fetched. Summarizing...\")\n",
    "    summary = summarize_text(paper_content)\n",
    "    if summary:\n",
    "        print(\"\\nSummary:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"Failed to summarize the paper.\")\n",
    "\n",
    "    print(\"\\nExtracting keywords...\")\n",
    "    keywords = extract_keywords(paper_content)\n",
    "    print(\"Keywords:\", keywords)\n",
    "\n",
    "# Example file path (replace with the path to your downloaded PDF)\n",
    "pdf_path = \"heart_disease.pdf\"  # Replace with your PDF file path\n",
    "\n",
    "process_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 2.4/2.9 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 13.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
